# -*- coding: utf-8 -*-
"""k_NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ncBmZqJmSQS7MiZgLmDtdDBuBcNwisU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import precision_recall_fscore_support

train_datasets = [
    r"datasets/training/training_data_ID_numeric.csv",
    r"datasets/training/training_data_ID_numeric_adasyn.csv",
    r"datasets/training/training_data_ID_numeric_clusterbased.csv",
    r"datasets/training/training_data_ID_numeric_nearmiss.csv",
    r"datasets/training/training_data_ID_numeric_smote.csv"
]

# Test ve validation veri setleri
test_data = pd.read_csv(r"datasets/test/test_data_ID_numeric.csv").drop(columns=['ID'])
validation_data = pd.read_csv(r"datasets/validation/validation_data_ID_numeric.csv").drop(columns=['ID'])

X_test = test_data.iloc[:, :-1].values 
y_test = test_data.iloc[:, -1].values 

X_val = validation_data.iloc[:, :-1].values 
y_val = validation_data.iloc[:, -1].values

# Define class weights
class_weights = {0: 1, 1: 3.5}


all_knn_classifiers = []

# Her bir eğitim datasetini ayrı ayrı işle
for dataset_path in train_datasets:
    # train sette IDyi dropla, her model için optimal k değeri bul.
    train_data = pd.read_csv(dataset_path).drop(columns=['ID'])

    X_train = train_data.iloc[:, :-1].values  # independent variables
    y_train = train_data.iloc[:, -1].values  # column label

    print(f"\n=== İşlenen Dataset: {dataset_path} ===")

    # Optimal k değerini bul
    k_values = range(1, 31)
    accuracies = []

    #1-31 arası k değerleri kullanılarak model oluşturulur
    #X_val değerleriyle tahmin edilir, y_val değeriyle karşılaştırılır.
    for k in k_values:
        knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')
        knn.fit(X_train, y_train)
        y_val_pred = knn.predict(X_val)
        accuracy = accuracy_score(y_val, y_val_pred)
        accuracies.append(accuracy)

    # Optimal k değerini seç
    optimal_k = np.argmax(accuracies) + 1
    print(f"Optimal k (validation set): {optimal_k}")

    # Validasyon doğruluklarını görselleştir
    plt.figure(figsize=(10, 6))
    plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b')
    plt.axvline(optimal_k, color='r', linestyle='--', label=f'Optimal k = {optimal_k}')
    plt.title(f'Validation Accuracy vs. k (Dataset: {dataset_path})')
    plt.xlabel('k Value')
    plt.ylabel('Validation Accuracy')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Optimal k ile validation ve test setlerinde doğruluk oranlarını hesapla
    final_knn = KNeighborsClassifier(n_neighbors=optimal_k, metric='euclidean')
    final_knn.fit(X_train, y_train)
    all_knn_classifiers.append((f'knn_{dataset_path}', final_knn))

    # Validation doğruluğu
    y_val_pred = final_knn.predict(X_val)
    val_accuracy = accuracy_score(y_val, y_val_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='macro')
    print(f"Validation Set Accuracy: {val_accuracy:.4f}")
    print(f"Validation Set Precision: {precision:.4f}")
    print(f"Validation Set Recall: {recall:.4f}")
    print(f"Validation Set F1 Score: {f1:.4f}")

    # Test doğruluğu
    y_test_pred = final_knn.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='macro')
    print(f"Test Set Accuracy: {test_accuracy:.4f}")
    print(f"Test Set Precision: {precision:.4f}")
    print(f"Test Set Recall: {recall:.4f}")
    print(f"Test Set F1 Score: {f1:.4f}")

    # Test sonuçlarını değerlendir
    conf_matrix_test = confusion_matrix(y_test, y_test_pred)
    plt.figure(figsize=(10, 8))  # Heatmap boyutunu ayarlama
    sns.heatmap(conf_matrix_test, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
    plt.title(f'Confusion Matrix (Test Set, Optimal k={optimal_k})')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
    print("\nClassification Report (Test Set):\n", classification_report(y_test, y_test_pred))

    # Validation sonuçlarını değerlendir
    conf_matrix_val = confusion_matrix(y_val, y_val_pred)
    plt.figure(figsize=(10, 8))  # Heatmap boyutunu ayarlama
    sns.heatmap(conf_matrix_val, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
    plt.title(f'Confusion Matrix (Validation Set, Optimal k={optimal_k})')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()
    print("\nClassification Report (Validation Set):\n", classification_report(y_val, y_val_pred))

print("Finished processing all datasets.")

# Additional model with weight factor
weighted_dataset_path = r"datasets/training/training_data_ID_numeric.csv"
weighted_train_data = pd.read_csv(weighted_dataset_path).drop(columns=['ID'])

X_weighted_train = weighted_train_data.iloc[:, :-1].values  # independent variables
y_weighted_train = weighted_train_data.iloc[:, -1].values  # column label

# Train the weighted KNN model
weighted_knn = KNeighborsClassifier(n_neighbors=optimal_k, metric='euclidean')
weighted_knn.fit(X_weighted_train, y_weighted_train)
all_knn_classifiers.append(('weighted_knn', weighted_knn))

#print("Trained weighted KNN model.")

# Create the ensemble with all KNN models
ensemble_knn = VotingClassifier(estimators=all_knn_classifiers, voting='soft')
ensemble_knn.fit(X_weighted_train, y_weighted_train)

#print("Created and fitted the ensemble model.")

# Validation doğruluğu
y_val_pred = ensemble_knn.predict(X_val)
val_accuracy = accuracy_score(y_val, y_val_pred)
precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='macro')
print(f"Validation Metrics (Ensemble Model):")
print(f"Accuracy: {val_accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:  {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Test doğruluğu
y_test_pred = ensemble_knn.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='macro')

print(f"Test Metrics (Ensemble Model):")
print(f"Accuracy : {test_accuracy:.4f}")
print(f"Precision : {precision:.4f}")
print(f"Recall : {recall:.4f}")
print(f"F1 Score : {f1:.4f}")

# Test sonuçlarını değerlendir
conf_matrix_test = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(10, 8))  # Heatmap boyutunu ayarlama
sns.heatmap(conf_matrix_test, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title(f'Confusion Matrix (Test Set, Ensemble Model)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
#print("\nClassification Report (Test Set, Ensemble Model):\n", classification_report(y_test, y_test_pred))

# Validation sonuçlarını değerlendir
conf_matrix_val = confusion_matrix(y_val, y_val_pred)
plt.figure(figsize=(10, 8))  # Heatmap boyutunu ayarlama
sns.heatmap(conf_matrix_val, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title(f'Confusion Matrix (Validation Set, Ensemble Model)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
#print("\nClassification Report (Validation Set, Ensemble Model):\n", classification_report(y_val, y_val_pred))